{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6859922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from autogen_core.models import UserMessage, AssistantMessage, SystemMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from datetime import datetime\n",
    "\n",
    "with open('gemini_key.txt', 'r') as f:\n",
    "    gemini_key = f.read().strip()\n",
    "\n",
    "gemini_llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"gemini-1.5-flash-8b\", \n",
    "            \"api_key\": gemini_key,  \n",
    "            \"api_type\": \"google\",\n",
    "        }\n",
    "    ],\n",
    "    \"cache_seed\": None,  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab7fa46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'description': 'Save user input to mock database',\n",
       "   'name': 'save_data',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'value': {'type': 'string', 'description': 'value'}},\n",
       "    'required': ['value']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'description': 'Show all saved data from mock database',\n",
       "   'name': 'show_stored_data',\n",
       "   'parameters': {'type': 'object', 'properties': {}, 'required': []}}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MockDatabase:\n",
    "    def __init__(self):\n",
    "        self._storage = [\"ex1\", \"ex2\", \"ex3\"]\n",
    "\n",
    "    def save(self, value: str) -> str:\n",
    "        self._storage.append(value)\n",
    "        return f\"Data saved: {value}\"\n",
    "        \n",
    "    def get_all(self) -> list:\n",
    "        return self._storage\n",
    "\n",
    "mock_db = MockDatabase()\n",
    "\n",
    "def save_data(value: str) -> str:\n",
    "    return mock_db.save(value)\n",
    "\n",
    "def show_stored_data() -> list:\n",
    "    return mock_db.get_all()\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "assistant = ConversableAgent(\n",
    "    name=\"Assistant\",\n",
    "    system_message=\"You are a helpful AI assistant. \"\n",
    "    \"You can save user input and show previously stored data.\",\n",
    "    llm_config=gemini_llm_config,\n",
    ")\n",
    "\n",
    "user_proxy = ConversableAgent(\n",
    "    name=\"User\",\n",
    "    llm_config=False,\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "assistant.register_for_llm(name=\"save_data\", description=\"Save user input to mock database\")(save_data)\n",
    "assistant.register_for_llm(name=\"show_stored_data\", description=\"Show all stored data\")(show_stored_data)\n",
    "user_proxy.register_for_execution(name=\"save_data\")(save_data)\n",
    "user_proxy.register_for_execution(name=\"show_stored_data\")(show_stored_data)\n",
    "\n",
    "from autogen import register_function\n",
    "\n",
    "register_function(\n",
    "    save_data,\n",
    "    caller=assistant,\n",
    "    executor=user_proxy,\n",
    "    name=\"save_data\",\n",
    "    description=\"Save user input to mock database\",\n",
    ")\n",
    "\n",
    "register_function(\n",
    "    show_stored_data,\n",
    "    caller=assistant,  \n",
    "    executor=user_proxy,  \n",
    "    name=\"show_stored_data\",  \n",
    "    description=\"Show all saved data from mock database\",  \n",
    ")\n",
    "assistant.llm_config[\"tools\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "427600cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "show me all stored data.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\n",
      "\u001b[32m***** Suggested tool call (3094): show_stored_data *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION show_stored_data...\n",
      "Call ID: 3094\n",
      "Input arguments: {}\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTED FUNCTION show_stored_data...\n",
      "Call ID: 3094\n",
      "Input arguments: {}\n",
      "Output:\n",
      "['ex1', 'ex2', 'ex3']\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (3094) *****\u001b[0m\n",
      "['ex1', 'ex2', 'ex3']\n",
      "\u001b[32m*********************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "OK.  What would you like me to do next?\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "OK.  What would you like me to do now?\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "OK.  What would you like me to do?\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "OK.  What would you like me to do?\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    },
    {
     "ename": "ServerError",
     "evalue": "500 INTERNAL. {'error': {'code': 500, 'message': 'Internal error encountered.', 'status': 'INTERNAL'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mServerError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m chat_result = \u001b[43muser_proxy\u001b[49m\u001b[43m.\u001b[49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43massistant\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshow me all stored data.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1481\u001b[39m, in \u001b[36mConversableAgent.initiate_chat\u001b[39m\u001b[34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[39m\n\u001b[32m   1479\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1480\u001b[39m         msg2send = \u001b[38;5;28mself\u001b[39m.generate_init_message(message, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1481\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1482\u001b[39m summary = \u001b[38;5;28mself\u001b[39m._summarize_chat(\n\u001b[32m   1483\u001b[39m     summary_method,\n\u001b[32m   1484\u001b[39m     summary_args,\n\u001b[32m   1485\u001b[39m     recipient,\n\u001b[32m   1486\u001b[39m     cache=cache,\n\u001b[32m   1487\u001b[39m )\n\u001b[32m   1488\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1161\u001b[39m, in \u001b[36mConversableAgent.send\u001b[39m\u001b[34m(self, message, recipient, request_reply, silent)\u001b[39m\n\u001b[32m   1159\u001b[39m valid = \u001b[38;5;28mself\u001b[39m._append_oai_message(message, \u001b[33m\"\u001b[39m\u001b[33massistant\u001b[39m\u001b[33m\"\u001b[39m, recipient, is_sending=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[32m-> \u001b[39m\u001b[32m1161\u001b[39m     \u001b[43mrecipient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1163\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1164\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMessage can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1165\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1271\u001b[39m, in \u001b[36mConversableAgent.receive\u001b[39m\u001b[34m(self, message, sender, request_reply, silent)\u001b[39m\n\u001b[32m   1269\u001b[39m reply = \u001b[38;5;28mself\u001b[39m.generate_reply(messages=\u001b[38;5;28mself\u001b[39m.chat_messages[sender], sender=sender)\n\u001b[32m   1270\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1271\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1161\u001b[39m, in \u001b[36mConversableAgent.send\u001b[39m\u001b[34m(self, message, recipient, request_reply, silent)\u001b[39m\n\u001b[32m   1159\u001b[39m valid = \u001b[38;5;28mself\u001b[39m._append_oai_message(message, \u001b[33m\"\u001b[39m\u001b[33massistant\u001b[39m\u001b[33m\"\u001b[39m, recipient, is_sending=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[32m-> \u001b[39m\u001b[32m1161\u001b[39m     \u001b[43mrecipient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1163\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1164\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMessage can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1165\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1271\u001b[39m, in \u001b[36mConversableAgent.receive\u001b[39m\u001b[34m(self, message, sender, request_reply, silent)\u001b[39m\n\u001b[32m   1269\u001b[39m reply = \u001b[38;5;28mself\u001b[39m.generate_reply(messages=\u001b[38;5;28mself\u001b[39m.chat_messages[sender], sender=sender)\n\u001b[32m   1270\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1271\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping similar frames: ConversableAgent.send at line 1161 (8 times), ConversableAgent.receive at line 1271 (7 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1271\u001b[39m, in \u001b[36mConversableAgent.receive\u001b[39m\u001b[34m(self, message, sender, request_reply, silent)\u001b[39m\n\u001b[32m   1269\u001b[39m reply = \u001b[38;5;28mself\u001b[39m.generate_reply(messages=\u001b[38;5;28mself\u001b[39m.chat_messages[sender], sender=sender)\n\u001b[32m   1270\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1271\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1161\u001b[39m, in \u001b[36mConversableAgent.send\u001b[39m\u001b[34m(self, message, recipient, request_reply, silent)\u001b[39m\n\u001b[32m   1159\u001b[39m valid = \u001b[38;5;28mself\u001b[39m._append_oai_message(message, \u001b[33m\"\u001b[39m\u001b[33massistant\u001b[39m\u001b[33m\"\u001b[39m, recipient, is_sending=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[32m-> \u001b[39m\u001b[32m1161\u001b[39m     \u001b[43mrecipient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1163\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1164\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMessage can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1165\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1269\u001b[39m, in \u001b[36mConversableAgent.receive\u001b[39m\u001b[34m(self, message, sender, request_reply, silent)\u001b[39m\n\u001b[32m   1267\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1269\u001b[39m reply = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m=\u001b[49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1270\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1271\u001b[39m     \u001b[38;5;28mself\u001b[39m.send(reply, sender, silent=silent)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:2826\u001b[39m, in \u001b[36mConversableAgent.generate_reply\u001b[39m\u001b[34m(self, messages, sender, **kwargs)\u001b[39m\n\u001b[32m   2824\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   2825\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._match_trigger(reply_func_tuple[\u001b[33m\"\u001b[39m\u001b[33mtrigger\u001b[39m\u001b[33m\"\u001b[39m], sender):\n\u001b[32m-> \u001b[39m\u001b[32m2826\u001b[39m     final, reply = \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m=\u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfig\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[32m   2828\u001b[39m         log_event(\n\u001b[32m   2829\u001b[39m             \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2830\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreply_func_executed\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2834\u001b[39m             reply=reply,\n\u001b[32m   2835\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:2153\u001b[39m, in \u001b[36mConversableAgent.generate_oai_reply\u001b[39m\u001b[34m(self, messages, sender, config)\u001b[39m\n\u001b[32m   2151\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m messages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2152\u001b[39m     messages = \u001b[38;5;28mself\u001b[39m._oai_messages[sender]\n\u001b[32m-> \u001b[39m\u001b[32m2153\u001b[39m extracted_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_oai_reply_from_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_oai_system_message\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient_cache\u001b[49m\n\u001b[32m   2155\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2156\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, extracted_response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:2172\u001b[39m, in \u001b[36mConversableAgent._generate_oai_reply_from_client\u001b[39m\u001b[34m(self, llm_client, messages, cache)\u001b[39m\n\u001b[32m   2169\u001b[39m         all_messages.append(message)\n\u001b[32m   2171\u001b[39m \u001b[38;5;66;03m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2172\u001b[39m response = \u001b[43mllm_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2173\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2174\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2175\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2176\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2177\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2178\u001b[39m extracted_response = llm_client.extract_text_or_completion_object(response)[\u001b[32m0\u001b[39m]\n\u001b[32m   2180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\autogen\\oai\\client.py:1155\u001b[39m, in \u001b[36mOpenAIWrapper.create\u001b[39m\u001b[34m(self, **config)\u001b[39m\n\u001b[32m   1153\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1154\u001b[39m     request_ts = get_current_ts()\n\u001b[32m-> \u001b[39m\u001b[32m1155\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1157\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m openai_result.is_successful:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\autogen\\oai\\gemini.py:316\u001b[39m, in \u001b[36mGeminiClient.create\u001b[39m\u001b[34m(self, params)\u001b[39m\n\u001b[32m    308\u001b[39m     generate_content_config = GenerateContentConfig(\n\u001b[32m    309\u001b[39m         safety_settings=safety_settings,\n\u001b[32m    310\u001b[39m         system_instruction=system_instruction,\n\u001b[32m   (...)\u001b[39m\u001b[32m    313\u001b[39m         **generation_config,\n\u001b[32m    314\u001b[39m     )\n\u001b[32m    315\u001b[39m     chat = client.chats.create(model=model_name, config=generate_content_config, history=gemini_messages[:-\u001b[32m1\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     response = \u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgemini_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[38;5;66;03m# Extract text and tools from response\u001b[39;00m\n\u001b[32m    319\u001b[39m ans = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\google\\genai\\chats.py:254\u001b[39m, in \u001b[36mChat.send_message\u001b[39m\u001b[34m(self, message, config)\u001b[39m\n\u001b[32m    249\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    250\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMessage must be a valid part type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes.PartUnion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    251\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes.PartUnionDict\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(message)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    252\u001b[39m   )\n\u001b[32m    253\u001b[39m input_content = t.t_content(\u001b[38;5;28mself\u001b[39m._modules._api_client, message)\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_modules\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_curated_history\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_content\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    259\u001b[39m model_output = (\n\u001b[32m    260\u001b[39m     [response.candidates[\u001b[32m0\u001b[39m].content]\n\u001b[32m    261\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.candidates \u001b[38;5;129;01mand\u001b[39;00m response.candidates[\u001b[32m0\u001b[39m].content\n\u001b[32m    262\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m    263\u001b[39m )\n\u001b[32m    264\u001b[39m automatic_function_calling_history = (\n\u001b[32m    265\u001b[39m     response.automatic_function_calling_history\n\u001b[32m    266\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.automatic_function_calling_history\n\u001b[32m    267\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m    268\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\google\\genai\\models.py:6058\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   6056\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc > \u001b[32m0\u001b[39m:\n\u001b[32m   6057\u001b[39m   i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m6058\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   6059\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   6060\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6061\u001b[39m   logger.info(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAFC remote call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is done.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   6062\u001b[39m   remaining_remote_calls_afc -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\google\\genai\\models.py:5007\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5004\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   5005\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m5007\u001b[39m response_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5008\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   5009\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5011\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_client.vertexai:\n\u001b[32m   5012\u001b[39m   response_dict = _GenerateContentResponse_from_vertex(\n\u001b[32m   5013\u001b[39m       \u001b[38;5;28mself\u001b[39m._api_client, response_dict\n\u001b[32m   5014\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\google\\genai\\_api_client.py:927\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m    918\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    919\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    923\u001b[39m ) -> Union[BaseResponse, Any]:\n\u001b[32m    924\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m    925\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m    926\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    928\u001b[39m   json_response = response.json\n\u001b[32m    929\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m json_response:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\google\\genai\\_api_client.py:793\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m    785\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    786\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m    787\u001b[39m       method=http_request.method,\n\u001b[32m    788\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    791\u001b[39m       timeout=http_request.timeout,\n\u001b[32m    792\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m   \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m    795\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m    796\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Susanna\\Documents\\Workspace\\AI_Montagna\\env\\Lib\\site-packages\\google\\genai\\errors.py:106\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    104\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    108\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(status_code, response_json, response)\n",
      "\u001b[31mServerError\u001b[39m: 500 INTERNAL. {'error': {'code': 500, 'message': 'Internal error encountered.', 'status': 'INTERNAL'}}"
     ]
    }
   ],
   "source": [
    "chat_result = user_proxy.initiate_chat(assistant,message=\"show me all stored data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b286f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockDatabase:\n",
    "    def __init__(self):\n",
    "        self._storage = [\"ex1\", \"ex2\", \"ex3\"]\n",
    "\n",
    "    def save(self, value: str) -> str:\n",
    "        self._storage.append(value)\n",
    "        return f\"Data saved: {value}\"\n",
    "        \n",
    "    def get_all(self) -> list:\n",
    "        return self._storage\n",
    "\n",
    "mock_db = MockDatabase()\n",
    "\n",
    "async def save_data(value: str) -> str:\n",
    "    return mock_db.save(value)\n",
    "\n",
    "async def get_data() -> list:\n",
    "    return mock_db.get_all()\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gemini-1.5-flash-8b\",\n",
    "    api_key=gemini_key,\n",
    ")\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[save_data, get_data],\n",
    "    system_message=\"You are a professional assistant. Use the provided tools to save and return user data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a86d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextMessage(source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 6, 18, 19, 10, 8, 765958, tzinfo=datetime.timezone.utc), content=\"save 'ex5' and then get all saved data\", type='TextMessage'), ToolCallRequestEvent(source='assistant', models_usage=RequestUsage(prompt_tokens=61, completion_tokens=9), metadata={}, created_at=datetime.datetime(2025, 6, 18, 19, 10, 9, 613337, tzinfo=datetime.timezone.utc), content=[FunctionCall(id='', arguments='{\"value\":\"ex5\"}', name='save_data'), FunctionCall(id='', arguments='{}', name='get_data')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='assistant', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 6, 18, 19, 10, 9, 613337, tzinfo=datetime.timezone.utc), content=[FunctionExecutionResult(content='Data saved: ex5', name='save_data', call_id='', is_error=False), FunctionExecutionResult(content=\"['ex1', 'ex2', 'ex3', 'ex5']\", name='get_data', call_id='', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='assistant', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 6, 18, 19, 10, 9, 613337, tzinfo=datetime.timezone.utc), content=\"Data saved: ex5\\n['ex1', 'ex2', 'ex3', 'ex5']\", type='ToolCallSummaryMessage', tool_calls=[FunctionCall(id='', arguments='{\"value\":\"ex5\"}', name='save_data'), FunctionCall(id='', arguments='{}', name='get_data')], results=[FunctionExecutionResult(content='Data saved: ex5', name='save_data', call_id='', is_error=False), FunctionExecutionResult(content=\"['ex1', 'ex2', 'ex3', 'ex5']\", name='get_data', call_id='', is_error=False)])]\n",
      "Data saved: ex5\n",
      "['ex1', 'ex2', 'ex3', 'ex5']\n"
     ]
    }
   ],
   "source": [
    "result = await agent.run(task=\"save 'ex5' and then get all saved data\")\n",
    "print(result.messages)\n",
    "print(result.messages[-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
